# gemini-chatbot
**Gemini Chatbot**
A conversational AI chatbot powered by Googleâ€™s Gemini 1.5 Flash model, built in Python using the google-generativeai SDK. This project demonstrates how to interact with advanced LLMs in real time, with neatly formatted outputs in Google Colab.


ğŸ“Œ Features
ğŸ’¬ Real-time chat with Gemini 1.5 Flash
ğŸ§  Maintains conversational context
ğŸ“„ Markdown-formatted, wrapped responses for clean Colab display
âš ï¸ Graceful error handling
âœ… Easy to run â€” just plug in your API key

ğŸ”§ Setup Instructions
Install required library
In a Colab cell:
python
Copy
Edit
!pip install -q google-generativeai
Get your API key
Visit: Google AI Studio
Create an API key
Add it to the code:
python
Copy
Edit
genai.configure(api_key="YOUR_API_KEY")
Run the chatbot

ğŸ’¡ Tech Stack
Google Gemini 1.5 Flash (Generative Model)
google-generativeai Python SDK
Google Colab
IPython display.Markdown for formatting
textwrap for clean line wrapping

ğŸ“¸ Example
vbnet
Copy
Edit
You: What is the capital of France?
Gemini:
The capital of France is Paris.

ğŸ›  Code Overview
Starts a chat session using GenerativeModel
Continuously accepts user input
Handles response formatting with textwrap and Markdown
Ends session cleanly on "exit"

ğŸ—‚ï¸ File Structure
bash
Copy
Edit
gemini-chatbot/
â”œâ”€â”€ gemini_chatbot.ipynb   # Main Colab notebook
â”œâ”€â”€ README.md              # Documentation
ğŸ“„ License
MIT License â€” Free to use and modify.
